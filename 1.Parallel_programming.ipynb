{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1aace1b-44a0-4f40-acd1-9bf395bc4ce9",
   "metadata": {},
   "source": [
    "<a href=\"https://www.dask.org/\" target=\"_blank\">\n",
    "<img src=\"http://dask.readthedocs.io/en/latest/_images/dask_horizontal.svg\"\n",
    "     align=\"right\"\n",
    "     width=\"30%\"\n",
    "     alt=\"Dask logo\\\">\n",
    "</a>\n",
    "\n",
    "# Parallel programming\n",
    "\n",
    "In this notebook, we will explain how Dask enables the parallelization of basic sequential programs throught domain decomposition (data parallelism) and functional decomposition (task parallelism).\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "Dask is a **library for parallel/distributed computing** in Python. \n",
    "\n",
    "* Python users can achieve **data parallelism**, by using Dask libraries such as `Dask Array` (mimic Numpy), `Dask DataFrame` (mimic Pandas), or `Dask Bag` (for large lists).\n",
    "* Users can also achieve **task parallelism** by using libraries such as `Dask Delayed`.\n",
    "\n",
    "**Content**\n",
    "\n",
    "1. What is parallel programming\n",
    "2. Problem decomposition strategies\n",
    "3. Example\n",
    "\n",
    "**Learning outcomes**\n",
    "* Define parallel programmming\n",
    "* Describe parallel programmming most common problem decomposition strategies.\n",
    "* Identify which Dask data structures enable domain and functional decomposition.\n",
    "* Exemplifies in which basic cases it is not worth parallelizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c12917-9c62-4aa9-a5d3-7e2fc7f4dd9e",
   "metadata": {},
   "source": [
    "## 1. What is parallel programming\n",
    "\n",
    "Parallel programmming is the use of two or more processor/cores in combination to solve a single problem.\n",
    "\n",
    "In order to use two or more processor/cores **we must divivde the problem**.\n",
    "\n",
    "Parallel programming is about **divide and conquer**, that is partitioning the problem in order to feed this partitions (chunks) into multiple processors in a single machine or a distributed system. Then processors can perform computations on these partitions at the same time.\n",
    "\n",
    "| Sequential programming                                                                                        | Parallel programming                                                                                        |\n",
    "|---------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|\n",
    "| The problem was **NOT** devided by the programmer                                                            | The problem was divided by the programmer                                                                   |\n",
    "| <img src=\"https://raw.githubusercontent.com/DonAurelio/dask-tutorial-2023/main/img/sequential_programming.png\"> | <img src=\"https://raw.githubusercontent.com/DonAurelio/dask-tutorial-2023/main/img/parallel_programming.png\"> |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ec3d35a-ff94-4225-8874-353d4d67e7b2",
   "metadata": {},
   "source": [
    "# 2. Problem decomposition strategies\n",
    "\n",
    "Problem decomposition (or division) is how parallel computing is achieved. Two decomposition strateties dominate when dealing with scientific and data analysis computations: domain and functional decomposition. \n",
    "\n",
    "**Domain decomposition or Data parallelism**\n",
    "\n",
    "* The main idea is to **partition the domain of the problem**. In scientific computing, the problem domain is commonly represented via **vectors** and **matrices** whilst in data analystics, the problem domain is commonly represented via **data tables**.\n",
    "* Implies partitioning data to processes such that *a single portion of data is assigned to a single core* [1].\n",
    "* Implies the simulataneous execution of the same function (operation) across the elements of a dataset [2].\n",
    "\n",
    "**Figure:** *[Left]* The domain is partitioned into chunks. Chucks are represenetd by colors. Every chunk is feed into a single core. *[Right]* Chunks in the figure are represented by subtables. Every subtable is feed into a single core.\n",
    "\n",
    "| Array                                                                                                                             | Table                                                                                                                             |\n",
    "|-----------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|\n",
    "|                                                         |\n",
    "| <img src=\"https://raw.githubusercontent.com/DonAurelio/dask-tutorial-2023/main/img/domain_decomposition_array.png\" width=\"600px\"> | <img src=\"https://raw.githubusercontent.com/DonAurelio/dask-tutorial-2023/main/img/domain_decomposition_table.png\" width=\"600px\"> |\n",
    "\n",
    "\n",
    "**Functional decomposition or Task parallelism** \n",
    "\n",
    "* The main idea is to **divide the code** used to solve a problem. This is commonly acheved by identifing functions, operations or secctions of the code that are independent of others.\n",
    "* Implies partitioning code to processes such that *a single portion of code (e.g., a function) is assigned to a single core* [1].\n",
    "* Implies the simultaneous execution of multiple and different functions across the same or different data sets [2].\n",
    "\n",
    "**Figure:** *[Left]* The code represents the following ecuation $z = x^2 + y^2$ for $x=2$ and $y=4$. *[Right]* If the program is executed in a sequential approach, it will take 4 time steps. However, when considering functional decomposition, the same function `squared` can be applied in parallel to $2$ and $4$ since these values are independent. Then, the amount of time steps is reduced to 3.\n",
    "\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/DonAurelio/dask-tutorial-2023/main/img/functional_decomposition.png\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f30e6-f3b2-43a2-8317-9dbd1b41ae28",
   "metadata": {},
   "source": [
    "## 3. Example\n",
    "\n",
    "**Problem**. Consider the following equation for arrays of shape `(1000, 1000)`. Suppose $x$ and $y$ are both matrices of ones.\n",
    "\n",
    "$$\n",
    "  z = x^2 + y^2\n",
    "$$\n",
    "\n",
    "We will solve the above mentioned problem using the following approaches:\n",
    "\n",
    "1. Sequential porgrammming\n",
    "2. Parallel programming: Automatic parallelization\n",
    "3. Parallel programming: Domain decomposition\n",
    "4. Parallel programming: Functional decomposition\n",
    "\n",
    "A the end of this notebook, you should be able to provide answers to the following questions:\n",
    "\n",
    "1. How many cores are we using when performing sequential programming?\n",
    "2. How many cores we are able to use with parallel programming?\n",
    "3. Which Dask data structure (Dask Array or Dask Delayed) enables domain decompositon for parallelziation?\n",
    "4. Which Dask data structure (Dask Array or Dask Delayed) enables functional decompositon for parallelization?\n",
    "5. Which parallelization strategy is the best (automatic paralleization, functional or domain decomposition) when considering the implemented algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a88910-cd9e-46cb-962d-74ffcdfbd483",
   "metadata": {},
   "source": [
    "### Sequential programming approach\n",
    "\n",
    "Open the file [matrix_sum_python.py](source/1/0.matrix_sum_python.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181d230-05b1-4c58-ba57-66401ad97093",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 -c 1 time -f 'Time: %e seconds \\nCPU usage: %P \\nMem usage: %M kbytes' \\\n",
    "python3.10 source/1/0.matrix_sum_python.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1657a5-3620-498e-906f-068c76e592a9",
   "metadata": {},
   "source": [
    "### Parallel programming approach: Automatic parallelization\n",
    "\n",
    "Open the file [matrix_sum_numpy.py](source/1/1.matrix_sum_numpy.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84a4b2-71c1-41bc-bc1a-f050a509da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 --exclusive time -f 'Time: %e seconds \\nCPU usage: %P \\nMem usage: %M kbytes' \\\n",
    "python3.10 source/1/1.matrix_sum_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13890e4-34f4-4f6c-be16-715a0b88fe5c",
   "metadata": {},
   "source": [
    "### Parallel programming approach: Domain decomposition\n",
    "\n",
    "In order to achieve parallelism, using the domain decomposition approach, we will use `Dask Array`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9850350-94c1-4f13-b0c5-e50f6ef3e0a3",
   "metadata": {},
   "source": [
    "__1. Import required libraries, define required variables and functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff5bb4-591e-40e6-86fe-8d8712164d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "shape = (1000,1000)\n",
    "chunks = (100,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaecc13-80fa-47d8-9844-373e382d7706",
   "metadata": {},
   "source": [
    "__2. Create the first array__ using `Dask Array` and perform domain decomposition. The `chucks` param tells Dask the size of every chuck in the decomposition. \n",
    "\n",
    "_Hint: Play with the `shape` and `chunks` params, observe the number of chucks created._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fe855-dbef-4939-b661-61a606a0767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = da.ones(shape=shape, chunks=chunks)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bbd12-1d73-49e7-adde-1375b49d210d",
   "metadata": {},
   "source": [
    "__3. Create the second array__ using `Dask Array` and perform domain decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7628e-eadf-411d-af0c-3d53fd98b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = da.ones(shape=shape, chunks=chunks)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76c1bdd-3ae3-432e-a981-842e5cf4997c",
   "metadata": {},
   "source": [
    "__3. Write the parallel version of the program__\n",
    "\n",
    "*Hint: you just need to write the equation $z = x^2 + y^2$ in Python langauge*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99af5142-6831-45f3-ba09-f021b384b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (x**2) + (y**2)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf0a08-05a4-43a4-bebf-f33f99d83b90",
   "metadata": {},
   "source": [
    "__3. Visualize the computations.__\n",
    "\n",
    "_Hint: These computations will be performed in all the cores available on your computer._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588203b8-0c5c-4523-a225-64e4e194b60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc37a3d-7848-4a8e-b09b-e1d00c296402",
   "metadata": {},
   "source": [
    "**5. Compute the result** of the equation.\n",
    "\n",
    "Open the file [matrix_sum_dask_array.py](source/1/2.matrix_sum_dask_array.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f951b-b71e-4847-b644-7b1ea979b35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 --exclusive time -f 'Time: %e seconds \\nCPU usage: %P \\nMem usage: %M kbytes' \\\n",
    "python3.10 source/1/2.matrix_sum_dask_array.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95172cef-526f-4ebc-9ada-b0efd41aa9df",
   "metadata": {},
   "source": [
    "### Parallel programming approach: Functional decomposition\n",
    "\n",
    "In order to achieve parallelism, using the functional decomposition approach, we will use `Dask Delayed`. However, **we need first to adjust our code** to be able to apply functional decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc490eee-8d94-4382-bde3-f8440ae90d36",
   "metadata": {},
   "source": [
    "__1. Import required libraries, define required variables and functions__\n",
    "\n",
    "**Remember the problem**. Consider the following equation for arrays of shape `(1000, 1000)`. Suppose $x$ and $y$ are both matrices of ones.\n",
    "\n",
    "$$\n",
    "  z = x^2 + y^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b41ac-389c-42ec-9933-802aa1b26e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "shape = (1000,1000)\n",
    "\n",
    "def create_array():\n",
    "    return [ [1 for x in range(0,shape[0])] for y in range(0,shape[1]) ]\n",
    "\n",
    "def square(a):\n",
    "    # __1. Square array (element-wise)__\n",
    "    return [ [ (a[x][y]**2) for x in range(0,shape[0])] for y in range(0,shape[1]) ]\n",
    "\n",
    "def add(a,b):\n",
    "    # __1. Addition (element-wise)__\n",
    "    return [ [ (a[x][y] + b[x][y]) for x in range(0,shape[0])] for y in range(0,shape[1]) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c574558-468a-4d10-ad50-5ef968e00a6e",
   "metadata": {},
   "source": [
    "__2. Write the equation in terms of functions by using Delayed__\n",
    "\n",
    "_Hint: you just need to write the equation $z = x^2 + y^2$ in Python langauge, but using the functions `squared` and `add` in place of `**` and `+`._\n",
    "\n",
    "**Step 1.** Write the equation in terms of functions using plain Python.\n",
    "\n",
    "```python\n",
    "x = create_array()\n",
    "y = create_array()\n",
    "a = square(x)\n",
    "b = square(y)\n",
    "c = add(a,b)\n",
    "```\n",
    "\n",
    "**Step 2.** Convert functions into delayed objects.\n",
    "\n",
    "```python\n",
    "x = dask.delayed(create_array)()\n",
    "y = dask.delayed(create_array)()\n",
    "a = dask.delayed(square)(x)\n",
    "b = dask.delayed(square)(y)\n",
    "c = dask.delayed(add)(a,b)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8709d7-393f-40dd-8964-26550b7d6ee8",
   "metadata": {},
   "source": [
    "__4. Run the parallel version of the program__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc5f007-7070-4248-b25f-629577a8c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dask.delayed(create_array)()\n",
    "y = dask.delayed(create_array)()\n",
    "a = dask.delayed(square)(x)\n",
    "b = dask.delayed(square)(y)\n",
    "c = dask.delayed(add)(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c77dbc-f666-4279-bbb4-99b93bc45c3b",
   "metadata": {},
   "source": [
    "__5. Visualize the computations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952c345-2ec0-4a2a-afc3-43fdc3311573",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc6900b-4838-4d82-bc4d-63c09a8db3a9",
   "metadata": {},
   "source": [
    "__6. Execute the computation__\n",
    "\n",
    "Open the file [matrix_sum_dask_delayed.py](source/1/3.matrix_sum_dask_delayed.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad488c89-7d80-4aff-b198-5107de500233",
   "metadata": {},
   "outputs": [],
   "source": [
    "!srun -N 1 --exclusive time -f 'Time: %e seconds \\nCPU usage: %P \\nMem usage: %M kbytes' \\\n",
    "python3.10 source/1/3.matrix_sum_dask_delayed.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307da9a-d90b-4cfa-adc2-89aa968efcfd",
   "metadata": {},
   "source": [
    "# [Excerise 1](labs/Lab1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc87602-2230-4c1d-93eb-1bc37043f621",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. Vitorović, A., Tomašević, M. V., & Milutinović, V. M. (2014). Manual parallelization versus state-of-the-art parallelization techniques: The spec cpu2006 as a case study. In Advances in Computers (Vol. 92, pp. 203-251). Elsevier.\n",
    "2. Terrell, R. (2018). Concurrency in. NET: Modern patterns of concurrent and parallel programming. Simon and Schuster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
